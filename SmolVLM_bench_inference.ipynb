{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:49.312602Z",
     "iopub.status.busy": "2025-01-31T18:08:49.312336Z",
     "iopub.status.idle": "2025-01-31T18:08:51.791917Z",
     "shell.execute_reply": "2025-01-31T18:08:51.791008Z",
     "shell.execute_reply.started": "2025-01-31T18:08:49.312577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn as nn\n",
    "import lens\n",
    "import polars as pl\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:51.793190Z",
     "iopub.status.busy": "2025-01-31T18:08:51.792817Z",
     "iopub.status.idle": "2025-01-31T18:08:51.796505Z",
     "shell.execute_reply": "2025-01-31T18:08:51.795865Z",
     "shell.execute_reply.started": "2025-01-31T18:08:51.793163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = 'test_save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.025511Z",
     "iopub.status.busy": "2025-01-31T18:08:56.024986Z",
     "iopub.status.idle": "2025-01-31T18:08:56.031158Z",
     "shell.execute_reply": "2025-01-31T18:08:56.030376Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.025486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x15d9a6690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.032231Z",
     "iopub.status.busy": "2025-01-31T18:08:56.031959Z",
     "iopub.status.idle": "2025-01-31T18:08:56.069481Z",
     "shell.execute_reply": "2025-01-31T18:08:56.068655Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.032199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    device = 'mps'\n",
    "else: device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.072212Z",
     "iopub.status.busy": "2025-01-31T18:08:56.071962Z",
     "iopub.status.idle": "2025-01-31T18:08:58.564388Z",
     "shell.execute_reply": "2025-01-31T18:08:58.563667Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.072191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели и процессора\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-500M-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-500M-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    #_attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:58.565510Z",
     "iopub.status.busy": "2025-01-31T18:08:58.565293Z",
     "iopub.status.idle": "2025-01-31T18:08:58.570713Z",
     "shell.execute_reply": "2025-01-31T18:08:58.569898Z",
     "shell.execute_reply.started": "2025-01-31T18:08:58.565492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_lens = lens.LogitLens(model.model.text_model.layers, model.lm_head, tokenizer=processor.tokenizer, processor=processor, output_attentions=True)\n",
    "text_lens.register()\n",
    "\n",
    "vision_lens = lens.LogitLens(model.model.vision_model.encoder.layers, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "vision_lens.register()\n",
    "\n",
    "projector_lens = lens.LogitLens(model.model.connector, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "projector_lens.register()\n",
    "\n",
    "vision_embedding_lens = lens.LogitLens(model.model.vision_model.embeddings.patch_embedding, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "vision_embedding_lens.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:58.571675Z",
     "iopub.status.busy": "2025-01-31T18:08:58.571470Z",
     "iopub.status.idle": "2025-01-31T18:08:59.598001Z",
     "shell.execute_reply": "2025-01-31T18:08:59.597338Z",
     "shell.execute_reply.started": "2025-01-31T18:08:58.571658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pl.read_parquet('hf://datasets/Lin-Chen/MMStar/mmstar.parquet').sample(250, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_parquet('sampled_data_250.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-31T18:12:13.064Z",
     "iopub.execute_input": "2025-01-31T18:08:59.599083Z",
     "iopub.status.busy": "2025-01-31T18:08:59.598787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [22:12<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "to_np = lambda data: np.array([x.cpu().float() for x in data.activations.values()], dtype=np.float16)\n",
    "\n",
    "for i, question, answer, category, l2_category, image, meta_info in tqdm(df.iter_rows(), total=len(df)):\n",
    "    image = Image.open(io.BytesIO(image))\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question}\n",
    "        ]\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\" : \"text\", \"text\": \"The answer is \"}]\n",
    "    }]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False)\n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    result = {\n",
    "        'text_lens': to_np(text_lens),\n",
    "        'vision_lens': to_np(vision_lens),\n",
    "        'embedding_lens': to_np(vision_embedding_lens),\n",
    "        'projector_lens': to_np(projector_lens)\n",
    "    }\n",
    "\n",
    "\n",
    "    np.savez(SAVE_PATH+f'{i}_saved_dictionary.npz', **result)\n",
    "\n",
    "    text_lens.cleanup()\n",
    "    vision_embedding_lens.cleanup()\n",
    "    vision_lens.cleanup()\n",
    "    projector_lens.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lens.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
