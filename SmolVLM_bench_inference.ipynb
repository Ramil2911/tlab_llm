{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:49.312602Z",
     "iopub.status.busy": "2025-01-31T18:08:49.312336Z",
     "iopub.status.idle": "2025-01-31T18:08:51.791917Z",
     "shell.execute_reply": "2025-01-31T18:08:51.791008Z",
     "shell.execute_reply.started": "2025-01-31T18:08:49.312577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogitLens:\n",
    "    def __init__(self, layers, head, tokenizer=None, processor=None, output_attentions=False):\n",
    "        \"\"\"\n",
    "        Универсальный Logit Lens для анализа скрытых представлений.\n",
    "        :param layers: Список слоёв модели (например, transformer encoder layers)\n",
    "        :param head: Выходная голова для получения логитов\n",
    "        :param tokenizer: Токенизатор для текстового анализа\n",
    "        :param processor: Процессор изображений\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.head = head\n",
    "        self.tokenizer = tokenizer\n",
    "        self.processor = processor\n",
    "        self.activations = {}\n",
    "\n",
    "    def _register_hooks(self, modules: nn.Module | nn.ModuleList):\n",
    "        \"\"\" Устанавливает forward-хуки для сохранения активаций слоёв. \"\"\"\n",
    "        def hook_fn(module, inputs, outputs):\n",
    "            layer_idx = len(self.activations)\n",
    "            self.activations[layer_idx] = outputs[0].detach().cpu()\n",
    "        \n",
    "        if isinstance(modules, (list, nn.ModuleList)):\n",
    "            for module in modules:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "        else:\n",
    "            modules.register_forward_hook(hook_fn)\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\" Обнуляет прошлые активации. \n",
    "        \"\"\"\n",
    "        self.activations = {}\n",
    "\n",
    "    def register(self):\n",
    "        \"\"\" Подключает хуки и обнуляет прошлые активации. \n",
    "        \"\"\"\n",
    "        self.activations = {}\n",
    "        \n",
    "        self._register_hooks(self.layers)\n",
    "\n",
    "    \n",
    "    def visualize_text_predictions(self, norm=lambda x: x, top_k=5):\n",
    "        \"\"\" Визуализирует топ-K токенов на разных слоях в виде тепловой карты. \"\"\"\n",
    "        assert self.tokenizer, \"Не указан токенизатор!\"\n",
    "\n",
    "        logits_per_layer = {layer: self.head(norm(hidden)) for layer, hidden in self.activations.items()}\n",
    "        layers = list(logits_per_layer.keys())\n",
    "        num_layers = len(layers)\n",
    "        \n",
    "        probs_matrix = np.zeros((num_layers, top_k))\n",
    "        tokens_matrix = np.empty((num_layers, top_k), dtype=object)\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            logits = logits_per_layer[layer]\n",
    "            if logits.ndim == 1:\n",
    "                logits = logits[None, None, :]\n",
    "            if logits.ndim == 2:\n",
    "                logits = torch.unsqueeze(logits, 0)\n",
    "            probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "            top_probs, top_ids = probs.topk(top_k)\n",
    "            top_tokens = [self.tokenizer.convert_ids_to_tokens(tid.item()) for tid in top_ids[0]]\n",
    "            probs_matrix[i, :] = top_probs.cpu().detach().float().numpy()\n",
    "            tokens_matrix[i, :] = top_tokens\n",
    "        \n",
    "        plt.figure(figsize=(10, num_layers * 0.5))\n",
    "        ax = sns.heatmap(probs_matrix, annot=tokens_matrix, cmap=\"coolwarm\", fmt=\"\", xticklabels=False)\n",
    "        ax.set_yticklabels([f\"Layer {layer + 1}\" for layer in layers], rotation=0)\n",
    "        plt.title(\"Top-K Token Probabilities Across Layers\")\n",
    "        plt.xlabel(\"Top-K Tokens\")\n",
    "        plt.ylabel(\"Layers\")\n",
    "        plt.show()\n",
    "\n",
    "    def print_top1_per_layer(self, norm=lambda x: x, mask=None):\n",
    "        \"\"\"Выводит top-1 токен на каждом слое, скрывая ненужные токены по маске.\"\"\"\n",
    "        assert self.tokenizer, \"Не указан токенизатор!\"\n",
    "        \n",
    "        logits_per_layer = {layer: self.head(norm(hidden)) for layer, hidden in self.activations.items()}\n",
    "        layers = list(logits_per_layer.keys())\n",
    "        num_layers = len(layers)\n",
    "        max_tokens = max(logits.shape[1] for logits in logits_per_layer.values())\n",
    "        \n",
    "        probs_matrix = np.zeros((num_layers, max_tokens))\n",
    "        tokens_matrix = np.empty((num_layers, max_tokens), dtype=object)\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            logits = logits_per_layer[layer]\n",
    "            if logits.ndim == 1:\n",
    "                logits = logits[None, None, :]\n",
    "            if logits.ndim == 2:\n",
    "                logits = torch.unsqueeze(logits, 0)\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            top_ids = probs.argmax(dim=-1)  # Получаем индексы top-1 токена\n",
    "            \n",
    "            for token_idx in range(top_ids.shape[1]):\n",
    "                token_id = top_ids[0, token_idx].item()\n",
    "                token = self.tokenizer.convert_ids_to_tokens(token_id)\n",
    "                \n",
    "                if mask is None or mask[token_idx]:\n",
    "                    probs_matrix[i, token_idx] = probs[0, token_idx, token_id].cpu().detach().float().numpy()\n",
    "                    tokens_matrix[i, token_idx] = token\n",
    "                else:\n",
    "                    probs_matrix[i, token_idx] = 0\n",
    "                    tokens_matrix[i, token_idx] = \"\"\n",
    "\n",
    "        probs_print = list()\n",
    "        tokens_print = list()\n",
    "\n",
    "        for i in range(len(probs_matrix)):\n",
    "            order = probs_matrix[i].argsort()[::-1]\n",
    "            probs_print.append(probs_matrix[i][order[:10]])\n",
    "            tokens_print.append(tokens_matrix[i][order[:10]])\n",
    "\n",
    "        plt.figure(figsize=(20, num_layers * 0.5))\n",
    "        ax = sns.heatmap(np.array(probs_print), annot=np.array(tokens_print), cmap=\"coolwarm\", fmt=\"\", xticklabels=False)\n",
    "        ax.set_yticklabels([f\"Layer {layer + 1}\" for layer in layers], rotation=0)\n",
    "        plt.title(\"Top-1 Token Per Layer\")\n",
    "        plt.xlabel(\"Tokens\")\n",
    "        plt.ylabel(\"Layers\")\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def visualize_vision_features(self, num_channels=8):\n",
    "        \"\"\" Визуализирует 2D-карты активаций в vision encoder. \"\"\"\n",
    "        for layer, activation in self.activations.items():\n",
    "            activation = activation.cpu().detach().float().numpy()\n",
    "            if activation.ndim == 4:\n",
    "                activation = activation[0]\n",
    "                num_channels = min(num_channels, activation.shape[0])\n",
    "                fig, axes = plt.subplots(1, num_channels, figsize=(num_channels * 2, 2))\n",
    "                fig.suptitle(f\"Vision Layer {layer + 1}\")\n",
    "                for i in range(num_channels):\n",
    "                    ax = axes[i] if num_channels > 1 else axes\n",
    "                    sns.heatmap(activation[i], cmap=\"coolwarm\", ax=ax, cbar=False)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_title(f\"Ch {i}\")\n",
    "                plt.show()\n",
    "    \n",
    "    def visualize_pca(self):\n",
    "        \"\"\" PCA-анализ скрытых представлений \"\"\"\n",
    "        all_features = torch.cat([h.view(h.size(0), -1) for h in self.activations.values()], dim=0)\n",
    "        pca = PCA(n_components=2)\n",
    "        projected = pca.fit_transform(all_features.float().cpu().numpy())\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(projected[:, 0], projected[:, 1], alpha=0.5)\n",
    "        plt.title(\"PCA Projection of Hidden States\")\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.show()\n",
    "    \n",
    "    def cosine_distance_heatmap(self, norm=None):\n",
    "        \"\"\" Визуализирует матрицу косинусных расстояний между слоями. \"\"\"\n",
    "        layer_representations = [norm(h).view(h.size(0), -1).mean(dim=0) for h in self.activations.values()]\n",
    "        similarities = torch.stack([F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))\n",
    "                                    for x in layer_representations for y in layer_representations])\n",
    "        similarity_matrix = similarities.view(len(layer_representations), -1).detach().float().cpu().numpy()\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(similarity_matrix, cmap=\"coolwarm\", annot=True)\n",
    "        plt.title(\"Cosine Distance Between Layers\")\n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(\"Layer\")\n",
    "        plt.show()\n",
    "\n",
    "    def uncertainity(self, norm=None):\n",
    "        \"\"\" Визуализирует матрицу косинусных расстояний между слоями. \"\"\"\n",
    "        layer_representations = [norm(h).view(h.size(0), -1).mean(dim=0) for h in self.activations.values()]\n",
    "        similarities = torch.stack([F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))\n",
    "                                    for x in layer_representations for y in layer_representations])\n",
    "        similarity_matrix = similarities.view(len(layer_representations), -1).float().cpu().numpy()\n",
    "        return similarity_matrix.mean()\n",
    "\n",
    "    def show_patches(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:51.793190Z",
     "iopub.status.busy": "2025-01-31T18:08:51.792817Z",
     "iopub.status.idle": "2025-01-31T18:08:51.796505Z",
     "shell.execute_reply": "2025-01-31T18:08:51.795865Z",
     "shell.execute_reply.started": "2025-01-31T18:08:51.793163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = 'test_save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:51.797598Z",
     "iopub.status.busy": "2025-01-31T18:08:51.797295Z",
     "iopub.status.idle": "2025-01-31T18:08:56.024202Z",
     "shell.execute_reply": "2025-01-31T18:08:56.023248Z",
     "shell.execute_reply.started": "2025-01-31T18:08:51.797567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hq-t77vj4f4r7/Documents/PersonalProjects/tlab_llm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoTokenizer, AutoProcessor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import polars as pl\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.025511Z",
     "iopub.status.busy": "2025-01-31T18:08:56.024986Z",
     "iopub.status.idle": "2025-01-31T18:08:56.031158Z",
     "shell.execute_reply": "2025-01-31T18:08:56.030376Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.025486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x15d9a6690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.032231Z",
     "iopub.status.busy": "2025-01-31T18:08:56.031959Z",
     "iopub.status.idle": "2025-01-31T18:08:56.069481Z",
     "shell.execute_reply": "2025-01-31T18:08:56.068655Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.032199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    device = 'mps'\n",
    "else: device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:56.072212Z",
     "iopub.status.busy": "2025-01-31T18:08:56.071962Z",
     "iopub.status.idle": "2025-01-31T18:08:58.564388Z",
     "shell.execute_reply": "2025-01-31T18:08:58.563667Z",
     "shell.execute_reply.started": "2025-01-31T18:08:56.072191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели и процессора\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-500M-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-500M-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    #_attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:58.565510Z",
     "iopub.status.busy": "2025-01-31T18:08:58.565293Z",
     "iopub.status.idle": "2025-01-31T18:08:58.570713Z",
     "shell.execute_reply": "2025-01-31T18:08:58.569898Z",
     "shell.execute_reply.started": "2025-01-31T18:08:58.565492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_lens = LogitLens(model.model.text_model.layers, model.lm_head, tokenizer=processor.tokenizer, processor=processor, output_attentions=True)\n",
    "text_lens.register()\n",
    "\n",
    "vision_lens = LogitLens(model.model.vision_model.encoder.layers, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "vision_lens.register()\n",
    "\n",
    "projector_lens = LogitLens(model.model.connector, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "projector_lens.register()\n",
    "\n",
    "vision_embedding_lens = LogitLens(model.model.vision_model.embeddings.patch_embedding, model.lm_head, tokenizer=processor.tokenizer, processor=processor)\n",
    "vision_embedding_lens.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:08:58.571675Z",
     "iopub.status.busy": "2025-01-31T18:08:58.571470Z",
     "iopub.status.idle": "2025-01-31T18:08:59.598001Z",
     "shell.execute_reply": "2025-01-31T18:08:59.597338Z",
     "shell.execute_reply.started": "2025-01-31T18:08:58.571658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pl.read_parquet('hf://datasets/Lin-Chen/MMStar/mmstar.parquet').sample(250, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_parquet('sampled_data_250.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-31T18:12:13.064Z",
     "iopub.execute_input": "2025-01-31T18:08:59.599083Z",
     "iopub.status.busy": "2025-01-31T18:08:59.598787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [22:12<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "to_np = lambda data: np.array([x.cpu().float() for x in data.activations.values()], dtype=np.float16)\n",
    "\n",
    "for i, question, answer, category, l2_category, image, meta_info in tqdm(df.iter_rows(), total=len(df)):\n",
    "    image = Image.open(io.BytesIO(image))\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question}\n",
    "        ]\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\" : \"text\", \"text\": \"The answer is \"}]\n",
    "    }]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False)\n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    result = {\n",
    "        'text_lens': to_np(text_lens),\n",
    "        'vision_lens': to_np(vision_lens),\n",
    "        'embedding_lens': to_np(vision_embedding_lens),\n",
    "        'projector_lens': to_np(projector_lens)\n",
    "    }\n",
    "\n",
    "\n",
    "    np.savez(SAVE_PATH+f'{i}_saved_dictionary.npz', **result)\n",
    "\n",
    "    text_lens.cleanup()\n",
    "    vision_embedding_lens.cleanup()\n",
    "    vision_lens.cleanup()\n",
    "    projector_lens.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lens.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
